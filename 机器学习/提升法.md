---
title: 提升法
---

继承学习的思想是“三个臭皮匠，顶个诸葛亮”，但此结论有前提条件。如果这些臭皮匠的优缺点完全相同，则无论多少臭皮匠，也顶不过诸葛亮。

### 自适应提升法

最早的提升法为自适应提升法，仅适用于分类问题。

对于分类问题，考虑依次种 $M$ 棵树 $G_1(X),\dots ,G_M(X)$。

对于第 $m$ 棵树中错误分类的观测值，则在之后的第 $m+1$ 棵树中给予更大的权重，提升后续树对该错误分类观测值的关注度。

具体来说，可通过以下两种方法来加大错分观测值的权重：

1. **权重更新**：在定义基尼指数或信息熵的不纯度函数，以及在计算终节点的观测值时，均考虑不同观测值的权重。对于错分观测值，增加其权重。
2. **再抽样**：在种每棵决策树时，都使用从“加权的分布”中再抽样得到的数据。这需要先将每轮的权重标准化，使得权重之和为1.

这里来看一个例子：假设训练数据为 ${(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)}$，其中 $y_i \in \{0,1\}$ 表示样本的类别。其中 $y=1$ 表示正例，$y=0$ 表示反例。

AdaBoost算法可分为以下三步，而其中第二步又分为5小步。针对弱分类器 $m =1 ,\dots ,M$ 进行for循环：

1. **初始化权重**：令每个观测值的初始权重为 $w_i = \frac{1}{n}$，其中 $n$ 为观测值的总数。
2. 对于决策树 $m =1 ,\dots ,M$，进行以下操作：
   1. 使用观测值 $i$ 的当前权重 $w_i$，估计第 $m$ 棵决策树 $G_m(X)$
   2. 根据当前权重 $w_i$，并计算其在训练集上的错误率:

      $$
      \epsilon_m = \frac{\sum_{i=1}^n w_i \mathbb{I}(G_m(x_i) \neq y_i)}{\sum_{i=1}^n w_i}
      $$

      其中，分母为所有观测值的权重之和，而分子为错分观测值的权重之和。
   3. 计算正确分类的对数几率，即正确分类的概率 $1-\epsilon_m$ 除以错误分类的概率 $\epsilon_m$，得到：

      $$
      \alpha_m = \log\left(\frac{1-\epsilon_m}{\epsilon_m}\right)
      $$

   4. 更新观测值的权重：

      $$
      w_i \leftarrow w_i \cdot \exp[\alpha_m \cdot I(y_i \neq G_m(\mathbf{x}_i))]
      $$

   5. 将所有权重标准化，保证权重之和为1，即：

      $$
      w_i \leftarrow \frac{w_i}{\sum_{j=1}^n w_j}
      $$

3. 将每棵决策树的预测结果 $G_m(X)$，以对数几率 $\alpha_m$ 为权重，进行加权平均，得到最终的预测结果：

   $$
   G(\mathbf{x}) = \text{sign}\left[\sum_{m=1}^{M} \alpha_m G_m(\mathbf{x})\right]
   $$

   其中, $\text{sign}(\cdot)$为“符号函数” (sign function), 即

   $$
   \text{sign}(z) = \begin{cases}
   1 & \text{if } z \ge 0 \\
   -1 & \text{if } z < 0
   \end{cases}
   $$

   结果只有1和-1两种，对应两种 $y$ 的类别。下一个弱分类器的训练考虑上一次的权重，求出使得错分率最小的阈值函数，即 $G_{\{ \}}(X)$。

在AdaBoost算法的第2步中，进一步考察第4步观测值权重的变化：

**“弱分类器”(weak classifier)的错分率至少比随机猜测更低**，则几率
$\left(\frac{1 - err_m}{err_m}\right) > 1$，故对数几率 $\alpha_m = \ln\left(\frac{1 - err_m}{err_m}\right) > 0$。故权重更新公式可写为：

$$
w_i \leftarrow w_i \cdot \exp[\alpha_m \cdot I(y_i \neq G_m(\mathbf{x}_i))] =
\begin{cases}
w_i \cdot \left(\frac{1 - err_m}{err_m}\right) & \text{if } y_i \neq G_m(\mathbf{x}_i) \\
w_i & \text{if } y_i = G_m(\mathbf{x}_i)
\end{cases}
$$

分类错误的观测值权重增加 $\left(\frac{1 - err_m}{err_m}\right) > 1$ 倍，而分类正确的观测值权重不变。

为保持所有观测值的权重之和为1，分类正确的观测值权重相对地减小。

如果某观测值一直分类错误，则其权重将不断增加，表明算法越来越希
望能将此“顽固”或困难(hard)的观测值正确地分类。

![fix](/images/imageBoo.png)

由Adaboost的第三步：集成学习的最后结果**以加权多数票决定**，而权重为正确分类的对数几率 $\alpha_m = \ln\left(\frac{1 - err_m}{err_m}\right) > 0$

分类越正确的决策树，权重就越大。

现讲二分类问题的Adaboost算法推广到多分类问题：对于多分类问题，假设 $y \in \{1, 2, \dots, K\}$。

对分类问题的前两步算法与二分类问题基本相同，但最后进行加权多数投票的公式为

$$
G(\mathbf{x}) = \underset{y \in \{1, 2, \dots, K\}}{\operatorname{argmax}} \left[ \sum_{m=1}^{M} \alpha_m I(y = G_m(\mathbf{x})) \right]
$$

其中，给定特征向量 $X$，判断第 $m$ 棵树的预测结果 $G_m(X)$ 是否正确。然后再以正确分类的对数几率 $\alpha_m$ 作为权重，进行加权投票。

分别计算 $y = 1,2,\dots,K$ 所得票数，最后以得票最多的作为最后的预测结果。

AdaBoost 算法的作用机制需从偏差与方差的角度来考察。

一方面，由于每棵树均纠正上一棵树的错误，迫使分类器更加重视特征空间中错误分类的区域，故可降低偏差。

另一方面，由于AdaBoost 的最终预测结果为很多决策树的加权平均，也可达到降低方差的效果。

早期的AdaBoost算法通常使用树桩作为弱学习器，即只有一个根节点与两个终节点的决策树。

该决策树仅选择一个变量做一次分裂，一般为弱学习器。

由于树桩仅做一次分裂，故其偏差较大而方差较小，很难拟合。

但若使用树桩作为基学习器，则无法捕捉变量之间的“交互效应”(interaction effect，类似于线性回归的交互项)，故未必总能达到最好的预测效果。

AdaBoost 最基本的性质是它能在学习过程中不断减少训练误差，即在训练数据集上的分类误差率。

AdaBoost的训练误差界：

$$
\frac{1}{N} \sum_{i=1}^{N} I(G(x_i) \neq y_i) \leq \frac{1}{N} \sum_{i} \exp(-y_i f(x_i))
$$

### AdaBoost 算法的解释

可以认为AdaBoost 算法是模型为加法模型、损失函数为指数函数、学习算法为向前分布算法时的二类分类学习方法。

**向前分布算法：**

$$
f(x) = \sum_{m=1}^{M} \beta_m b(x; \gamma_m)
$$

其中, $b(x; \gamma_m)$ 为基函数, $\gamma_m$ 为基函数的参数, $\beta_m$ 为基函数的系数。显然, 上式是一个加法模型。

在给定训练数据及损失函数 $L(y,f(x))$ 的条件下，学习加法模型 $f(x)$ 成为损失函数极小化问题：

$$
\min_{\beta_m, \gamma_m} \sum_{i=1}^{N} L\left(y_i, \sum_{m=1}^{M} \beta_m b(x_i; \gamma_m)\right)
$$

通常这时一个非凸优化问题（变量太多，组合爆炸 。向前分布算法求解这一优化问题的想法是：因为学习的是加法模型，如果能够从前向后，每一步只学习一个基函数及其系数，逐步逼近目标函数式：也就是说：假设已学到第 $m-1$ 步的模型:

$$
f_{m-1}(x) = \sum_{k=1}^{m-1} \beta_k b(x; \gamma_k)
$$

第 $m$ 步的目标是找最优的 $\beta_m, \gamma_m$, 最小化损失:

$$
\min_{\beta,\gamma} \sum_{i=1}^{N} L(y_i, f_{m-1}(x_i) + \beta b(x_i; \gamma))
$$

等价于优化:

$$
\min_{\beta,\gamma} \sum_{i=1}^{N} L(y_i, \beta b(x_i; \gamma))
$$

(因 $f_{m-1}(x_i)$ 是“已知的前 $m-1$ 步结果”, 可视为常数, 不影响 $\beta, \gamma$ 的优化)，这样，前向分布算法将同时求解从 $m=1$ 到 $M$ 的所有参数 $\beta_m$，$\gamma_m$ 的优化问题简化为逐个求解各个 $\beta_m$ ，$\gamma_m$ 的优化问题。

**前向分布算法与AdaBoost**：AdaBoost 算法是前向分布算法的特例。这时，模型是由基本分类器组成的加法模型，损失函数是指数函数。推导如下：

前向分布算法学习的是加法模型，当基函数为基本分类器时，该加法模型等价于AdaBoost的最终分类器

$$
f(x) = \sum_{m=1}^{M} \alpha_m G_m(x)
$$

由基本分类器 $G_m(x)$ 及其系数 $\alpha_m$ 组成。前向分布算法逐一学习基函数，这一过程与AdaBoost算法逐一学习基本分类器的过程一致。

下面证明前向分布算法的损失函数时指数损失函数

$$
L(y, f(x)) = \exp[-y f(x)]
$$

时，其学习的具体操作等价于AdaBoost算法学习的具体操作。

假设已经经过了 $m-1$ 轮迭代前向分布算法，已经得到 $f_{m-1}(x)$：

$$
\begin{align*}
f_{m-1}(x) &= f_{m-2}(x) + \alpha_{m-1}G_{m-1}(x) \\
&= \alpha_1 G_1(x) + \dots + \alpha_{m-1}G_{m-1}(x)
\end{align*}
$$

在第 $m$ 轮迭代得到 $\alpha_m$，$G_m(x)$ 和 $f_m(x)$

$$
f_m(x) = f_{m-1}(x) + \alpha_m G_m(x)
$$

目标是使前向分布算法得到的 $\alpha_m$ 和 $G_m(x)$ 使 $f_m(x)$ 在训练数据集 $T$ 上的损失函数最小，即

$$
(\alpha_m, G_m(x)) = \arg\min_{\alpha, G} \sum_{i=1}^{N} \exp[-y_i(f_{m-1}(x_i) + \alpha G(x_i))]
$$

式子可以表示为：

$$
(\alpha_m, G_m(x)) = \arg\min_{\alpha, G} \sum_{i=1}^{N} \bar{w}_{mi} \exp[-y_i \alpha G(x_i)]
$$

其中, $\bar{w}_{mi} = \exp[-y_i f_{m-1}(x_i)]$。因为 $\bar{w}_{mi}$ 既不依赖 $\alpha$ 也不依赖于 $G$, 所以与最小化无关。但 $\bar{w}_{mi}$ 依赖于 $f_{m-1}(x)$, 随着每一轮迭代而发生改变。

现证使式上式达到最小的 $\alpha_m^*$ 和 $G_m^*(x)$ 就是 AdaBoost 算法所得到的 $\alpha_m$ 和 $G_m(x)$。求解可分两步:

1. 求 $G_(m)$
对固定 $\alpha > 0$, $\exp(-y_i \cdot \alpha \cdot G(x_i))$ 的值:

   - 若 $G(x_i) = y_i$ (分类正确), 则 $\exp(-y_i \cdot \alpha \cdot G(x_i)) = \exp(-\alpha)$;
   - 若 $G(x_i) \neq y_i$ (分类错误), 则 $\exp(-y_i \cdot \alpha \cdot G(x_i)) = \exp(\alpha)$。

   因此, 损失函数可改写为: $\sum_{i=1}^{N} \bar{w}_{mi} \cdot \exp(-y_i \cdot \alpha \cdot G(x_i)) = e^{-\alpha} \sum_{G(x_i)=y_i} \bar{w}_{mi} + e^{\alpha} \sum_{G(x_i) \neq y_i} \bar{w}_{mi}$

   为最小化该损失, 需让错误分类的样本权重和最小 (因 $e^{\alpha} > e^{-\alpha}$, 错误分类的损失更大)。因此, 最优基函数 $G_m^*(x)$ 是: $G_m^*(x) = \arg\min_G \sum_{i=1}^{N} \bar{w}_{mi} \cdot I(y_i \neq G(x_i))$

   这与 AdaBoost 中“用当前样本权重训练弱分类器”的逻辑完全一致

2. 将 $G_m^*(x)$ 代入损失函数, 可进一步简化为关于 $\alpha$ 的函数:

   $$
   \sum_{i=1}^{N} \bar{w}_{mi} \cdot \exp(-y_i \cdot \alpha \cdot G_m^*(x_i)) = e^{-\alpha} \sum_{\text{对分样本}} \bar{w}_{mi} + e^{\alpha} \sum_{\text{错分样本}} \bar{w}_{mi}
   $$

   对 $\alpha$ 求导并令导数为 0, 可解得最优系数: $\alpha_m = \frac{1}{2} \log\left(\frac{1-e_m}{e_m}\right)$

   其中 $e_m = \frac{\sum_{\text{错分样本}} \bar{w}_{mi}}{\sum_{i=1}^{N} \bar{w}_{mi}}$ 是加权错分率 (与 AdaBoost 中的 $err_m$ 一致)。

最后来看每一轮样本权值的更新。由

$$
f_m(x) = f_{m-1}(x) + \alpha_m G_m(x)
$$

以及 $\bar{w}_{mi} = \exp[-y_i f_{m-1}(x_i)]$, 可得

$$
\bar{w}_{m+1,i} = \bar{w}_{m,i} \exp[-y_i \alpha_m G_m(x)]
$$

### 提升树

以决策树为基函数的提升方法称为提升树。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。**提升树模型可以表示为决策树的加法模型：**

$$
f_M(x) = \sum_{m=1}^{M} T(x; \Theta_m)
$$

其中, $T(x; \Theta_m)$ 表示决策树, $\Theta_m$ 为决策树的参数, $M$ 为树的个数。

**提升树算法**：采用前向分布算法。首先确定初始提升树 $f_0(x) = 0$，第 $m$ 步的模型是

$$
f_m(x) = f_{m-1}(x) + T(x; \Theta_m)
$$

其中，$f_{m-1}(x)$ 为当前模型，通过风险函数极小化确定下一棵决策树的参数 $\Theta_m$

$$
\hat{\Theta}_m = \arg\min_{\Theta_m} \sum_{i=1}^N L\left(y_i, f_{m-1}(x_i) + T(x_i; \Theta_m)\right)
$$

由于树的线性组合可以很好的拟合训练数据，即使数据中的输入与输出之间的关系很复杂也是如此，所以提升树是一个高功能的学习算法。

对于不同问题的提升树学习算法，其主要区别在于损失函数的不同。包括使用平方误差损失的回归问题，用指数损失函数的分类问题，以及用一般损失函数的一般决策问题。

对于二分类问题，提升树算法只需要将 Adaboost算法中的基本分类器限制为二类分类树即可，上文的基本弱分类器可以看作是一个根结点直接连接两个叶结点的简单决策树，即所谓的决策树桩。提升树模型可以表示为决策树的加法模型：

可以说这时的提升树算法是 AdaBoost 算法的特殊情况。下面叙述回归问题的提升树。

已知一个训练数据集 $T = \{(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)\}$，$x_i \in \mathcal{X} \subseteq \mathbb{R}^n$，$\mathcal{X}$ 为输入空间，$y_i \in \mathcal{Y} \subseteq \mathbb{R}$，$\mathcal{Y}$ 为输出空间。如果将输入空间 $\mathcal{X}$ 划分为 $J$ 个互不相交的区域 $R_1, R_2, \ldots, R_J$，并且在每个区域上确定输出的常量 $c_j$，那么树可表示为

$$
T(x; \Theta) = \sum_{j=1}^J c_j I(x \in R_j)
$$

其中，参数 $\Theta = \{(R_1, c_1), (R_2, c_2), \ldots, (R_J, c_J)\}$ 表示树的区域划分和各区域上的常数。$J$ 是回归树的复杂度即叶结点个数。

**回归问题提升树使用以下前向分布算法：**

$$
\begin{align*}
f_0(x) &= 0 \\
f_m(x) &= f_{m - 1}(x) + T(x; \Theta_m), \quad m = 1, 2, \ldots, M \\
f_M(x) &= \sum_{m = 1}^M T(x; \Theta_m)
\end{align*}
$$

在前向分布算法的第 $m$ 步，给定当前模型 $f_{m-1}(X)$，需求解

$$
\hat{\Theta}_m = \arg\min_{\Theta_m} \sum_{i=1}^N L\left(y_i, f_{m - 1}(x_i) + T(x_i; \Theta_m)\right)
$$

得到 $\hat{\Theta}_m$，即第 $m$ 棵树的参数。

当采用平方误差损失函数时，即：

$$
L(y, f(x)) = (y - f(x))^2
$$

其损失变为

$$
\begin{align*}
L\left(y, f_{m - 1}(x) + T(x; \Theta_m)\right) &= \left[y - f_{m - 1}(x) - T(x; \Theta_m)\right]^2 \\
&= \left[r - T(x; \Theta_m)\right]^2
\end{align*}
$$

这里，

$$
r = y-f_{m-1}(x)
$$

时上一个模型拟合数据的残差。所以对回归问题的提升树算法来说，只需简单地拟合当前模型的残差。这样，算法是相当简单的。现将回归问题的提升树算法叙述如下：

**输入**：训练数据集 $T = \{(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)\}$，$x_i \in \mathcal{X} \subseteq \mathbb{R}^n$，$y_i \in \mathcal{Y} \subseteq \mathbb{R}$；  
**输出**：提升树 $f_M(x)$。  

1. 初始化 $f_0(x) = 0$  
2. 对 $m = 1, 2, \ldots, M$：  
   1. 计算残差

      $$
      r_{mi} = y_i - f_{m-1}(x_i), \quad i = 1, 2, \ldots, N
      $$

   2. 拟合残差 $r_{mi}$ 学习一个回归树，得到 $T(x; \Theta_m)$

   3. 更新 $f_m(x) = f_{m-1}(x) + T(x; \Theta_m)$  
3. 得到回归问题提升树  

$$
f_M(x) = \sum_{m=1}^M T(x; \Theta_m)$$

这里来看一个实例：学习以下回归问题的提升树模型，考虑只用树桩作为基函数

| $x_i$ | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| $y_i$ | 5.56 | 5.70 | 5.91 | 6.40 | 6.80 | 7.05 | 8.90 | 8.70 | 9.00 | 9.05 |

首先通过以下优化问题：

$$
\min_{s} \left[ \min_{c_1} \sum_{x_i \in R_1} (y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2} (y_i - c_2)^2 \right]
$$

求解训练数据的切分点 $s$：

$$
R_1 = \{x \mid x \leqslant s\}, \quad R_2 = \{x \mid x > s\}
$$

容易求得在 $R_1$，$R_2$ 内部使平方损失误差达到最小值的 $c_1$，$c_2$ 为

$$
c_1 = \frac{1}{N_1} \sum_{x_i \in R_1} y_i, \quad c_2 = \frac{1}{N_2} \sum_{x_i \in R_2} y_i
$$

这里 $N_1$，$N_2$ 是 $R_1$，$R_2$ 的样本点数。

求训练数据的切分点。根据所给数据，考虑如下切分点：

1.5，2.5，3.5，4.5，5.5，6.5，7.5，8.5，9.5

对各切分点，不难求出相应的 $\mathrm{R}_1$，$\mathrm{R}_2$，$c_1$，$c_2$ 及

$$
m(s)=\min_{c_1} \sum_{x_i \in R_1} (y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2} (y_i - c_2)^2
$$

例如，当 $s=1.5$时，$\mathrm{R}_1=\{1\}$，$\mathrm{R}_2=\{2,3,\ldots,10\}$，$c_1=5.56$，$c_2=7.50$，

$$
m(s)=\min_{c_1} \sum_{x_i \in R_1} (y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2} (y_i - c_2)^2 = 0 + 15.72 = 15.72
$$

现将 $s$ 及 $m(s)$ 的计算结果列表如下

| $s$   | 1.5  | 2.5  | 3.5  | 4.5  | 5.5  | 6.5  | 7.5  | 8.5  | 9.5  |
|-------|------|------|------|------|------|------|------|------|------|
| $m(s)$ | 15.72 | 12.07 | 8.36 | 5.78 | 3.91 | 1.93 | 8.01 | 11.73 | 15.74 |

由上表可知，当 $s = 6.5 $时 $m(s)$ 达到最小值，此时 $\mathrm{R}_1 = \{1,2,\ldots,6\}$，$\mathrm{R}_2 = \{7,8,9,10\}$，$c_1 = 6.24$，$c_2 = 8.91$，所以回归树 $T_1(x)$ 为

$$
T_1(x) = \begin{cases}
6.24, & x < 6.5 \\
8.91, & x \geqslant 6.5
\end{cases}
$$

$$
f_1(x) = T_1(x)
$$

用 $f_1(x)$ 拟合训练数据的残差见下表，表中 $r_{2i} = y_i - f_1(x_i)$，$i = 1,2,\ldots,10$。

| $x_i$ | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| $r_{2i}$ | -0.68 | -0.54 | -0.33 | 0.16 | 0.56 | 0.81 | -0.01 | -0.21 | 0.09 | 0.14 |

将这里的 $r_{2i}$ 作为新的 $y$ 值，继续进行第一步操作，求出一组新的 $c_i$ 和 $c_2$ 作为 $T_2(x)$。

$$
T_2(x) = \begin{cases}
-0.52, & x < 3.5 \\
0.22, & x \geqslant 3.5
\end{cases}
$$

$$
f_2(x) = f_1(x) + T_2(x) = \begin{cases}
5.72, & x < 3.5 \\
6.46, & 3.5 \leqslant x < 6.5 \\
9.13, & x \geqslant 6.5
\end{cases}
$$

用 $f_2(x)$ 拟合训练数据的平方损失误差是  

$$
L(y, f_2(x)) = \sum_{i=1}^{10} (y_i - f_2(x_i))^2 = 0.79
$$

继续求得  

$$
T_3(x) = \begin{cases}
0.15, & x < 6.5 \\
-0.22, & x \geqslant 6.5
\end{cases} \quad L(y, f_3(x)) = 0.47
$$  

$$
T_4(x) = \begin{cases}
-0.16, & x < 4.5 \\
0.11, & x \geqslant 4.5
\end{cases} \quad L(y, f_4(x)) = 0.30
$$  

$$
T_5(x) = \begin{cases}
0.07, & x < 6.5 \\
-0.11, & x \geqslant 6.5
\end{cases} \quad L(y, f_5(x)) = 0.23
$$  

$$
T_6(x) = \begin{cases}
-0.15, & x < 2.5 \\
0.04, & x \geqslant 2.5
\end{cases}
$$  

$$
\begin{align*}
f_6(x) &= f_5(x) + T_6(x) = T_1(x) + \cdots + T_5(x) + T_6(x) \\
&= \begin{cases}
5.63, & x < 2.5 \\
5.82, & 2.5 \leqslant x < 3.5 \\
6.56, & 3.5 \leqslant x < 4.5 \\
6.83, & 4.5 \leqslant x < 6.5 \\
8.95, & x \geqslant 6.5
\end{cases}
\end{align*}
$$

用 $f_6(x)$ 拟合训练数据的平方损失误差是  

$$
L(y, f_6(x)) = \sum_{i=1}^{10} (y_i - f_6(x_i))^2 = 0.17
$$

假设此时已满足误差要求，那么 $f(x) = f_6(x)$ 即为所求提升树。

### 梯度提升

提升树利用加法模型与前向分布算法实现学习的优化过程。当损失函数是平方损失和指数损失时，每一步的优化是很简单的。但对一般损失函数而言，往往每一步优化并不那么容易。针对这一问题提出了梯度提升算法。这是利用最速下降法的近似方法，其关键是利用损失函数的负梯度在当前模型的值

$$
-\left[ \frac{\partial L(y, f(x_i))}{\partial f(x_i)} \right]_{f(x) = f_{m - 1}(x)}
$$

作为**回归问题提升树算法中的残差的近似值**，拟合一个回归树。

输入: 训练数据集 $T = \{(x_1, y_1), (x_2, y_2), \dots, (x_N, y_N)\}$, $x_i \in \mathcal{X} \subseteq \mathbb{R}^n$, $y_i \in \mathcal{Y} \subseteq \mathbb{R}$; 损失函数 $L(y, f(x))$

输出: 回归树 $\hat{f}(x)$

1. 初始化

$$
f_0(x) = \arg\min_c \sum_{i=1}^{N} L(y_i, c)
$$

2. 对 m=1,2,...,M
   1. 对 i=1,2,...,N, 计算

   $$
   r_{mi} = -\left[\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}\right]_{f(x)=f_{m-1}(x)}
   $$

   2. 对 $r_{mi}$ 拟合一个回归树, 得到第 $m$ 棵树的叶结点区域 $R_{mj}$, j=1,2,...,J
   3. 对 j=1,2,...,J, 计算

   $$
   c_{mj} = \arg\min_c \sum_{x_i \in R_{mj}} L(y_i, f_{m-1}(x_i) + c)
   $$

   4. 更新 $f_m(x) = f_{m-1}(x) + \sum_{j=1}^{J} c_{mj} I(x \in R_{mj})$

3. 得到回归树
$$
\hat{f}(x) = f_M(x) = \sum_{m=1}^{M} \sum_{j=1}^{J} c_{mj} I(x \in R_{mj})
$$

### 案例

**AdaBoost算法步骤**

1. **初始化样本权重**  
   给每个训练样本 $(x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N)$ 分配初始权重：  
   $$w_{1i} = \frac{1}{N} \quad (i = 1, 2, \ldots, N)$$  
   其中 $N$ 为样本总数。

2. **迭代训练弱学习器**  
   对于 $m = 1, 2, \ldots, M$（$M$ 为预设迭代次数）：  
   - **训练当前弱学习器**：基于权重分布 $w_m$ 训练弱学习器 $G_m(x)$，使其在加权样本上达到较低的错误率。  
   - **计算误分率**：  
     $$e_m = \sum_{i=1}^N w_{mi} \cdot I(y_i \neq G_m(x_i))$$  
     其中 $I(\cdot)$ 为指示函数（条件为真时取 1，否则取 0）。  
   - **计算学习器权重**：  
     $$\alpha_m = \frac{1}{2} \log\left(\frac{1 - e_m}{e_m}\right)$$  
     （$e_m$ 越小，$\alpha_m$ 越大，表明该学习器在最终模型中占比越高）。  
   - **更新样本权重**：  
     $$w_{m+1,i} = \frac{w_{mi} \cdot \exp(-\alpha_m \cdot y_i \cdot G_m(x_i))}{Z_m}$$  
     其中 $Z_m = \sum_{i=1}^N w_{mi} \cdot \exp(-\alpha_m \cdot y_i \cdot G_m(x_i))$ 为归一化因子，确保 $w_{m+1}$ 是合法的概率分布。

3. **组合弱学习器**  
   最终的强学习器为所有弱学习器的加权组合：  
   $$G(x) = \text{sign}\left(\sum_{m=1}^M \alpha_m \cdot G_m(x)\right)$$  
   其中 $\text{sign}(\cdot)$ 为符号函数（输出值为正取 1，负取 -1）。

```python
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
%matplotlib inline
# 图形会直接显示在代码单元格的下方，与代码和输出内容融为一体 不需要plt.show()
```

```python
# 数据
def create_data():
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    data = np.array(df.iloc[:100,[0,1,-1]]) # 读取第一列 第二列和最后一列
    for i in range(len(data)): #将标签为0的类改为-1
        if data[i,-1] == 0:
            data[i,-1] = -1
    return data[:,:2],data[:,-1]
```

```python
X,y = create_data()
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)

plt.scatter(X[:50,0],X[:50,1],label = '0')
plt.scatter(X[50:,0],X[50:,1],label = '1')
plt.legend()
```

![fix](/images/imageBoo-1.png)

```python
class AdaBoost:
    def __init__(self,n_estimators=50,learning_rate=1.0):
        self.clf_num = n_estimators
        self.learning_rate = learning_rate

    def init_args(self,datasets,labels):
        self.X = datasets
        self.y = labels
        self.M,self.N = datasets.shape
        #弱分类器数目集合
        self.clf_sets = []
        #初始化权重
        self.weights = [1.0 / self.M]*self.M #这里是令权重为 1/M 并储存到一个集合，再将这个集合生成M个
        #G(X)系数alpha
        self.alpha = []

    def _G(self,features,labels,weights): #下划线开头表示私有方法（仅类内部使用）
        m = len(features)
        error = 100000.0 #无穷大
        best_v = 0.0 #初始化划分阈值
        features_min = min(features)
        features_max = max(features)
        n_step = (features_max - features_min +
                  self.learning_rate) // self.learning_rate #步数 划分阈值从0开始按步长（学习率）增加
        direct ,compare_array = None,None
        for i in range(1,int(n_step)):
            v = features_min +self.learning_rate *i

            if v not in features: #只处理 "不在特征值中" 的阈值（避免阈值正好落在某个样本的特征值上，确保划分有意义）
                # 误分类计算
                compare_array_positive = np.array(
                    [1 if features[k]>v else -1 for k in range(m)]) #大于阈值定义为1 否则为-1
                compare_array_nagetive = np.array(
                    [-1 if features[k]>v else 1 for k in range(m)]) #与正向相反
                weight_error_positive = sum([
                weights[k] for k in range(m)
                if compare_array_positive[k] != labels[k]]) #将所有预测错误的样本的权重相加 对应公式中的error

                weight_error_nagetive = sum([
                    weights[k] for k in range(m)
                    if compare_array_nagetive[k] != labels[k]])
                if weight_error_positive < weight_error_nagetive:
                    weight_error = weight_error_positive
                    _compare_array = compare_array_positive
                    direct = 'positive'
                else:
                    weight_error = weight_error_nagetive
                    _compare_array = compare_array_nagetive
                    direct = 'nagetive'

                if weight_error < error:
                    error = weight_error
                    compare_array = _compare_array
                    best_v = v
        return best_v , direct,error,compare_array
        # 计算alpha

    def _alpha(self,error):
        return 0.5 *np.log((1-error)/error)
        # 规范化因子

    def _Z(self,weights,a,clf):
        return sum([
            weights[i]* np.exp(-1 * a * self.y[i] * clf[i])
            for i in range(self.M)
        ])
        # 权重更新

    def _w(self,a,clf,Z):
        for i in range(self.M):
            self.weights[i] = self.weights[i] * np.exp(-1*a*self.y[i]*clf[i])/Z

    def _f(self,x,v,clf_sets):
        pass

    def G(self,x,v,direct):
        if direct == 'positive':
            return 1 if x>v else -1
        else:
            return -1 if x>v else 1

    def fit(self,X,y):
        self.init_args(X,y)

        for epoch in range(self.clf_num): #弱分类器的个数 默认50个
            best_clf_error,best_v,clf_result = 10000,None,None
            # 根据特征维度, 选择误差最小的
            for j in range(self.N):
                features = self.X[:,j]
                v,direct,error,compare_array = self._G(features,self.y,self.weights)

                if error<best_clf_error:
                    best_clf_error = error
                    best_v = v
                    final_direct = direct
                    clf_result = compare_array
                    axis = j

                if best_clf_error == 0:
                    break

            a = self._alpha(best_clf_error)
            self.alpha.append(a)
            self.clf_sets.append((axis,best_v,final_direct))
            z = self._Z(self.weights,a,clf_result)
            self._w(a,clf_result,z) #更新权重

    def predict(self,feature):
        result = 0.0
        for i in range(len(self.clf_sets)):
            axis,clf_v,direct = self.clf_sets[i]
            f_input = feature[axis]
            result += self.alpha[i] *self.G(f_input,clf_v,direct)

        return 1 if result>0 else -1

    def score(self,X_test,y_test):
        right_count = 0
        for i in range(len(X_test)):
            feature = X_test[i]
            if self.predict(feature) == y_test[i]:
                right_count += 1

        return right_count /len(X_test)
```

先用案例数据：

```python
X = np.arange(10).reshape(10, 1)
y = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])
clf = AdaBoost(n_estimators=3, learning_rate=0.5)
clf.fit(X, y)
```

使用iris数据

```python
X, y = create_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33) #若不指定种子参数，每次运行时打乱的顺序不同。结果的最终得到的 X_train/X_test 和 y_train/y_test 数据分布会有差异。

clf = AdaBoost(n_estimators=10, learning_rate=0.2)
clf.fit(X_train, y_train)
clf.score(X_test, y_test)

0.8181818181818182

```

使用sklearn.ensemble：

```python
from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier(n_estimators=100,learning_rate=0.5)
clf.fit(X_train,y_train)

clf.score(X_test,y_test)

0.9393939393939394
```

例：某公司招聘职员考查身体、业务能力、发展潜力这3项。身体分为合格1、不合格0两级，业务能力和发展潜力分为上1、中2、下3三级分类为合格1 、不合格-1两类。已知10个人的数据，如下表所示。假设弱分类器为决策树桩。试用AdaBoost算法学习一个强分类器。

应聘人员情况数据表
| 序号 | 身体 | 业务 | 潜力 | 分类 |
| ---- | ---- | ---- | ---- | ---- |
| 1    | 0    | 1    | 3    | -1   |
| 2    | 0    | 3    | 1    | -1   |
| 3    | 1    | 2    | 2    | -1   |
| 4    | 1    | 1    | 3    | -1   |
| 5    | 1    | 2    | 3    | -1   |
| 6    | 0    | 1    | 2    | -1   |
| 7    | 1    | 1    | 2    | 1    |
| 8    | 1    | 1    | 1    | 1    |
| 9    | 1    | 3    | 1    | -1   |
| 10   | 0    | 2    | 1    | -1   |

```python
import numpy as np

# 加载训练数据
X = np.array([[0, 1, 3], [0, 3, 1], [1, 2, 2], [1, 1, 3], [1, 2, 3], [0, 1, 2],
              [1, 1, 2], [1, 1, 1], [1, 3, 1], [0, 2, 1]])
y = np.array([-1, -1, -1, -1, -1, -1, 1, 1, -1, -1])
X.shape
```

sklearn的AdaBoost Classifier分类器直接求解:

```python
from sklearn.ensemble import AdaBoostClassifier

clf = AdaBoostClassifier()
clf.fit(X, y)
y_predict = clf.predict(X)
score = clf.score(X, y)
print("原始输出:", y)
print("预测输出:", y_predict)
print("预测正确率：{:.2%}".format(score))

原始输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测正确率：100.00%
```

自编程实现

```python
# 手搓自编程实现

import numpy as np

class AdaBoost:
    def __init__(self,X,y,tol=0.05,max_iter = 10):
        # 训练数据 实例
        self.X = X
        # 训练数据 标签
        self.y = y
        #终止条件
        self.tol = tol
        # 最大迭代次数
        self.max_iter = max_iter
        # 初始化样本权重w
        self.w = np.full((X.shape[0]),1/X.shape[0])
        self.G = [] # 弱分类器

    def build_stump(self):
        m,n = np.shape(self.X)
        e_min = np.inf #无穷大 不是值下确界
        sign = None
        best_stump={}
        for i in range(n): #对每一列进行分析
            range_min = self.X[:,i].min()
            range_max = self.X[:,i].max()
            step_size = (range_max-range_min)/n
            for j in range(-1,int(n)+1): #覆盖最小值前到最大值和后的所有范围
                thresh_val = range_min+j*step_size
                for inequal in ['lt','rt']:
                    predict_vals = self.base_estimator(self.X,i,thresh_val,inequal)
                    error_arr = np.array(np.ones(m)) #先将所有的都定义为1，如果预测正确则改为0
                    error_arr[predict_vals.T == self.y.T]=0
                    weighted_error = np.dot(self.w,error_arr)
                    if weighted_error < e_min:
                        e_min = weighted_error
                        sign = predict_vals
                        best_stump['dim'] = i
                        best_stump['thresh'] = thresh_val
                        best_stump['ineq'] = inequal
        return best_stump,sign,e_min

    def updata_w(self,alpha,predict):
        P = self.w*np.exp(-alpha*self.y*predict)
        self.w = P/P.sum()

    @staticmethod
    def base_estimator(X,dimen,threshVal,threshIneq):
        ret_array = np.ones(np.shape(X)[0])
        if threshIneq == 'lt':
            ret_array[X[:,dimen] <= threshVal] = -1.0
        else:
            ret_array[X[:,dimen]>threshVal] = -1.0
        return ret_array

    def fit(self):
        G = 0
        for i in range(self.max_iter):
            best_stump,sign,error = self.build_stump() #sign = G_i(X)
            alpha = 1/2 *np.log((1-error)/error)
            best_stump['alpha'] = alpha
            # 保存弱分类器
            self.G.append(best_stump)
            G += alpha*sign
            y_predict = np.sign(G)
            error_rate = np.sum(
                np.abs(y_predict-self.y)) /2 /self.y.shape[0]
            if error_rate < self.tol: #满足终止条件，跳出循环
                print("迭代次数:",i+1)
                break
            else:
                self.updata_w(alpha,y_predict) # 若不满足，更新权重继续迭代。

    def predict(self,X):
        m = np.shape(X)[0]
        G = np.zeros(m)
        for i in range(len(self.G)):
            stump = self.G[i]
            _G = self.base_estimator(X, stump['dim'], stump['thresh'],
                                     stump['ineq'])
            alpha = stump['alpha']
            G+=alpha *_G
        y_predict = np.sign(G)
        return y_predict.astype(int)

    def score(self, X, y):
        """对训练效果进行评价"""
        y_predict = self.predict(X)
        error_rate = np.sum(np.abs(y_predict - y)) / 2 / y.shape[0]
        return 1 - error_rate
```

```python
clf = AdaBoost(X, y)
clf.fit()
y_predict = clf.predict(X)
score = clf.score(X, y)
print("原始输出:", y)
print("预测输出:", y_predict)
print("预测正确率：{:.2%}".format(score))
print(clf.G)

迭代次数: 8
原始输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测正确率：100.00%
[{'dim': 0, 'thresh': -0.3333333333333333, 'ineq': 'rt', 'alpha': 0.6931471805599453}, {'dim': 1, 'thresh': 1.0, 'ineq': 'rt', 'alpha': 0.7331685343967135}, {'dim': 2, 'thresh': 1.0, 'ineq': 'rt', 'alpha': 0.49926441505556346}, {'dim': 0, 'thresh': 0.0, 'ineq': 'lt', 'alpha': 0.6235907793285863}, {'dim': 2, 'thresh': 2.333333333333333, 'ineq': 'rt', 'alpha': 0.7214232653124057}, {'dim': 2, 'thresh': 2.333333333333333, 'ineq': 'rt', 'alpha': 0.5575175335417657}, {'dim': 0, 'thresh': -0.3333333333333333, 'ineq': 'rt', 'alpha': 0.6021426339356153}, {'dim': 0, 'thresh': -0.3333333333333333, 'ineq': 'rt', 'alpha': 0.839721449526161}]
```

---
