# 大数定律与中心极限定理

## 简介

大数定律和中心极限定理是统计学中特别重要的性质，很多没有学过统计的同学虽然可能没有听过，但是一定在生活中，学习中，工作中用过了。
本文将对大数定律和中心极限定理进行简单介绍。

## 准备工作

本文不会告诉大家如何去证明大数定律和中心极限定理，对它们只会做出简单的描述，以至于让大家快速的理解。同时将以实例的形式，以python代码试验来说明大数定律
和中心极限定理的正确性。
既然需要以python代码来说明问题，那么首先介绍一下数据：

数据并非真实数据，而是由python自动生成的，先让生成数据的代码，然后再做简单介绍：

```python
import numpy as np

mean = [1,5, 15]
var = [[2,1, 5],[1,4, 0], [3, 5, 12]]
x,y,z = np.random.multivariate_normal(mean, var,1000).T

fp = open("data.in", 'w')
for line in x[:600]:
    fp.write(str(line)+'\n')
for line in y[:200]:
    fp.write(str(line) + '\n')
for line in z[:800]:
    fp.write(str(line) + '\n')

fp.close()
```

首先根据Numpy包里的random库里的多元变量高斯随机函数生成1000组数据，其中这三组数据的均值分别为1，5,15，然后分别只取其中的600,200,800个样本写入文件data.in
作为本文测试数据。

上面的操作想要达到的目的是得到的数据不能是正态分布，大家也可以采取其他方式获得数据。由于是随机产生，所以大家如果使用相同的代码跑出来的结果和本文示例的
结果也是不一样的，但是没关系，本文的结论不会受影响。

为保证结果可重复，本文将一次产生的数据全部存在了data/data.in下面，后面所有分析都是基于这个数据，该数据将作为后面的一个总体。

## 数据描述

首先说明，本文产生的数据确实不是正态分布，为此画出其密度分布图如下：
![](https://github.com/NGSHotpot/Statistics/blob/master/images/1.png)

同时使用python计算该总体数据的均值和标准差：

```python
import numpy as np
data = map(lambda x:x.split(), open("data.in").readlines())
data = [float(x[0]) for x in data]
mean = np.mean(data)
std = np.std(data, ddof=1)
print mean, std
```
上述代码可以得到总体的均值为8.5741820797894341，标准差为7.1909492667730008。

准备工作大致就到这里，然后本文将介绍大数定律和中心极限定理。

## 大数定律

若是有随机变量![equation](http://latex.codecogs.com/gif.latex?X_1,X_2,...,X_n)是独立同分布的，那么可计算这n个样本的样本均值：

![equation](http://latex.codecogs.com/gif.latex?\overline{X_n}=\frac{1}{n}(X_1+X_2+,...,+X_n))

该样本均值收敛于真值（真实的总体均值）。

![equation](http://latex.codecogs.com/gif.latex?\lim_{n\rightarrow\infty}{\overline{X_n}}=\mu)

在概率论中其描述为：当n趋近于无穷大时，样本均值依概率收敛于总体均值

![equation](http://latex.codecogs.com/gif.latex?\lim_{n\rightarrow\infty}{P(\vert{Y_n-E(Y_n)}\vert\geq\epsilon)}=0)


大致就是在说，当n很大的时候，样本均值趋近于总体均值。其实这个结论非常的符合人们的直观感受：比如给全校的男生量身高，由于各种原因没有办法测量所有人的身高，只能选出其中100个人测量，发现平均身高为170，一般就会得出结论说：这个学校的男生的平均身高为170。这其实使用的就是大数定律的结论。

为了验证大数定律，基于刚才提到的data.in数据，从中随机抽取不同数量的样本，然后看样本均值和总体均值的关系。

![](https://github.com/NGSHotpot/Statistics/blob/master/images/2.png)

上图中，中间的虚线代表总体均值，两种颜色分别代表两次测试。每一次测试的操作为：取不同的样本大小，从3到1000，然后求得样本均值。从图上可以看出样本均值
一直在总体均值附近波动，并且随着样本量的增大，样本均值随着总体均值波动的程度越小。这样也就验证了大数定律的结论，当样本量较大时，样本均值趋近于总体均值。

获得上述验证数据的python代码如下：

```python
import numpy as np

data = map(lambda x:x.split(), open("data.in").readlines())
data = [float(x[0]) for x in data]

fp = open("big.in", 'w')
fp.write("x\ty\ttype\n")

for n in range(3, 1000, 5):
    tmp = np.mean(np.random.choice(data, n))
    tmp2 = np.mean(np.random.choice(data, n))
    fp.write(str(n)+'\t'+str(tmp) + '\tx1\n')
    fp.write(str(n)+'\t'+str(tmp2)+'\tx2\n')
fp.close()

```

为了更好的展示上述结果，我们在上述两次测试中，计算每次和真实值的差异的绝对值，分别将差异绝对值画在真实值两次，能够更加好的展示结果。

![](https://github.com/NGSHotpot/Statistics/blob/master/images/4.png)

同样给出python代码

```python
import numpy as np

data = map(lambda x:x.split(), open("data.in").readlines())
data = [float(x[0]) for x in data]

fp = open("big2.in", 'w')
fp.write("x\ty\ttype\n")

totalMean = 8.5741820797894341

for n in range(3, 1000, 5):
    tmp = abs(np.mean(np.random.choice(data, n)) - totalMean) + totalMean
    tmp2 = totalMean - abs(np.mean(np.random.choice(data, n))-totalMean)
    fp.write(str(n)+'\t'+str(tmp) + '\tx1\n')
    fp.write(str(n)+'\t'+str(tmp2)+'\tx2\n')
fp.close()
```

## 中心极限定理

在说中心极限定理之前，先说样本标准差和总体标准差的关系，与大数定律中的样本均值与总体均值的关系类似，当样本量较大时，样本标准差趋近于总体标准差。
使用和上面类似的验证方式，我们做得如下图形：

![](https://github.com/NGSHotpot/Statistics/blob/master/images/3.png)

获得上述验证数据的python代码如下：

```python
import numpy as np

data = map(lambda x:x.split(), open("data.in").readlines())
data = [float(x[0]) for x in data]

fp = open("bigVar.in", 'w')
fp.write("x\ty\ttype\n")

for n in range(3, 1000, 5):
    tmp = np.std(np.random.choice(data, n), ddof=1)
    tmp2 = np.std(np.random.choice(data, n), ddof=1)
    fp.write(str(n)+'\t'+str(tmp) + '\tx1\n')
    fp.write(str(n)+'\t'+str(tmp2)+'\tx2\n')
fp.close()
```

为了更好的展示上述结果，我们在上述两次测试中，计算每次和真实值的差异的绝对值，分别将差异绝对值画在真实值两次，能够更加好的展示结果。

![](https://github.com/NGSHotpot/Statistics/blob/master/images/5.png)

同样给出python代码

```python
import numpy as np

data = map(lambda x:x.split(), open("data.in").readlines())
data = [float(x[0]) for x in data]

fp = open("bigVar2.in", 'w')
fp.write("x\ty\ttype\n")

totalVar = 7.1909492667730008

for n in range(3, 1000, 5):
    tmp = abs(np.std(np.random.choice(data, n), ddof=1)-totalVar) + totalVar
    tmp2 = totalVar - abs(np.std(np.random.choice(data, n), ddof=1)-totalVar)
    fp.write(str(n)+'\t'+str(tmp) + '\tx1\n')
    fp.write(str(n)+'\t'+str(tmp2)+'\tx2\n')
fp.close()
```

### 中心极限定理主要内容

若是有随机变量![equation](http://latex.codecogs.com/gif.latex?X_1,X_2,...,X_n)是独立同分布的，且总体的均值为：![equation](http://latex.codecogs.com/gif.latex?\mu),总体的方差为：![equation](http://latex.codecogs.com/gif.latex?\sigma^2)，定义

![equation](http://latex.codecogs.com/gif.latex?Y_n=\frac{\sum_{k=1}^{n}{X_k}-n\mu}{\sqrt{n}\sigma})

那么![equation](http://latex.codecogs.com/gif.latex?Y_n)收敛到均值为0，方差为1的正态分布。数学表示为：

![equation](http://latex.codecogs.com/gif.latex?\lim_{n\rightarrow\infty}P(Y_n\leq{x})=\frac{1}{\sqrt{2\pi}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}dt})

看着比较复杂，其实上述内容主要说了以下事情：

1. 当n趋近于无穷大时，样本均值的分布趋近于正态分布。
2. 上述正态分布的均值为总体均值：![equation](http://latex.codecogs.com/gif.latex?\mu)
3. 上述正态分布的方差与总体方差以及样本量大小相关：![equation](http://latex.codecogs.com/gif.latex?\frac{\sigma^2}{n})

### 实例测试

首先说第一点和第二点，当n较大时，样本均值趋近于正态分布。

在测试数据中，每次分别取10个样本和100个样本，分别计算均值，如此抽样1000次，然后将每次10个样本和每次100个样本的1000个均值分别看其密度分布，如下

![](https://github.com/NGSHotpot/Statistics/blob/master/images/6.png)

图上竖直的虚线代表总体均值，可以看出来其密度图像越来越接近与正态分布的密度函数。同时也看到了该分布的均值与总体均值基本相同。

代码如下：

```python
import numpy as np

data = map(lambda x:x.split(), open("data.in").readlines())
data = [float(x[0]) for x in data]

fp = open("meanDistribution.in", 'w')
fp.write("mean\ttype\n")

totalMean = 8.5741820797894341

nums = [10, 100]

for n in nums:
    for i in range(1000):
        tmp = np.mean(np.random.choice(data, n))
        fp.write(str(tmp) + '\tn=%d\n'%n)
fp.close()
```

下面说明第三点

同样做两次测试，如下图所示，红色为n在不同取值时![equation](http://latex.codecogs.com/gif.latex?\frac{\sigma^2}{n})的取值，另外两个颜色分别为两次测试的样本均值的方差。

![](https://github.com/NGSHotpot/Statistics/blob/master/images/7.png)


代码如下：

```python
import numpy as np
import math

data = map(lambda x:x.split(), open("data.in").readlines())
data = [float(x[0]) for x in data]

fp = open("meanVar.in", 'w')
fp.write("x\ty\ttype\n")

for n in range(3, 1000, 5):
    x1 = []
    x2 = []
    for i in range(100):
        tmp = np.mean(np.random.choice(data, n))
        tmp2 = np.mean(np.random.choice(data, n))
        x1.append(tmp)
        x2.append(tmp2)
    tmp = np.std(x1, ddof=1)
    tmp2 = np.std(x2, ddof=1)
    fp.write(str(n)+'\t'+str(tmp) + '\tx1\n')
    fp.write(str(n)+'\t'+str(tmp2)+'\tx2\n')
    fp.write(str(n)+'\t'+str(7.1909492667730008/math.sqrt(n*1.0)) + '\ttrue\n')
fp.close()
```

## 总结

说了这么多，总结一下应用：

当样本量足够大时：

1. 样本均值趋近于总体均值
2. 样本方差趋近于总体方差
3. 样本均值服从正态分布
4. 样本均值所服从的正态分布的均值为总体均值
5. 样本均值所服从的正态分布的方差乘上样本数量为总体方差

